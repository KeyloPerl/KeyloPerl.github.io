<!doctype html>
<html lang="en">
  <head>
  	<title>Keylo Perl</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link href="https://fonts.googleapis.com/css?family=Poppins:300,400,500,600,700,800,900" rel="stylesheet">
		
		<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.7.1/dist/jquery.slim.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"></script>
    <script src="js/prism.js"></script>
    <link rel="stylesheet" href="css/prism.css">
		<link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/my_style.css">
  </head>
  <body>
		
		<div class="wrapper d-flex align-items-stretch">
			<nav id="sidebar" class="sidebar-fix">
        
				<div class="p-4 pt-5">
		  		<a href="#" class="img logo rounded-circle mb-5" style="background-image: url(images/Keylo-small-e.jpg);"></a>
	        <ul class="list-unstyled components mb-5">
	          <li class="active">  
	            <a href="#homeSubmenu" data-toggle="collapse" aria-expanded="false" class="dropdown-toggle">Quickstart</a>
	            <ul class="collapse list-unstyled" id="homeSubmenu">
                <li>
                    <a href="#Overiew">Overview</a>
                </li>
                <li>
                    <a href="#Battery">Battery</a>
                </li>
                <li>
                    <a href="#Charging ">Charging</a>
                </li>
	            </ul>
	          </li>
            <li>
              <a href="#">Hardware Upgrades and Changes</a>
            </li>
	          <li>
              <a href="#pageSubmenu" data-toggle="collapse" aria-expanded="false" class="dropdown-toggle">ROS driver</a>
              <ul class="collapse list-unstyled" id="pageSubmenu">
                <li>
                    <a href="#">Basics</a>
                </li>
                <li>
                    <a href="#">Teleoperation</a>
                </li>
                <li>
                  <a href="#">Mapping</a>
              </li>
                <li>
                    <a href="#">Autonomous Navigation</a>
                </li>
                <li>
                  <a href="#">Realsense drivers</a>
                </li>
              </ul>
	          </li>
	          <li>
              <a href="#">Talking Avatar</a>
	          </li>
	          <li>
              <a href="#">Future Improvements</a>
	          </li>
	        </ul>



	      </div>
    	</nav>

        <!-- Page Content  -->
      <div id="content" class="p-4 p-md-5">

        <!--<nav class="navbar navbar-expand-lg navbar-light bg-light">-->
          
            <button type="button" id="sidebarCollapse" class="btn btn-primary button-fix">
              <i class="fa fa-bars"></i>
              <span class="sr-only">Toggle Menu</span>
            </button>
        
            <!--<button class="btn btn-dark d-inline-block d-lg-none ml-auto" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
                <i class="fa fa-bars"></i>
            </button>-->

        <!-- </nav> -->
        <img src="images/Keylo-small-e.jpg" style="display:block;margin-left:auto;margin-right: auto;"><br><br>
        <h2 class="mb-4">About the robot</h2>
        <p>Keylo is a robot build by WYCA robotics for the purpose of telepresense. <a href="https://www.generationrobots.com/media/Wyca%20Keylo%20data%20sheet%20VE-MAJ.pdf">Datasheet</a>. The robot is built with a touch screen display, 
        speakers and camera for interactions. With developements in AI, the Robot can be programmed to learn from its surroundings using the sensors and trained for
      intelligence. The robot can Autonomously navigate using its sensor, obtain various informations using sensors such as depth camera, range sensors, LIDAR sensor and MIC sensor to make intelligent decisions, human interaction, 
    robot planning and many more.  </p>
        <h2 class="mb-4">Quick start</h2>
        <p>The Robot is equipped with an Intel NUC CPU that runs ubuntu 18.04 with preinstalled ROS melodic (Now replaced with GEEKOM IT13 mini PC). Down below is an image of the CPU in the robot 
          connected to the touch screen display with HDMI cables. The new GEEKOM MiniPC is preinstalled with Windows 11 and dual booted with ubuntu 18.04 to support ROS melodic drivers.    
        </p> 
          <img src="images/CPU.jpg" style="height:auto;width:30%;display:block;margin-left:auto;margin-right:auto;"><br><br>
          <p>The USB hub on the robot is where the LIDAR, Depth cameras, speaker, touch display and arduino are connected.</p><br>
        <div class="row">  
          <img class="col-sm-4" src="images/USB_HUB.png" style="height:auto;width:30%;"><br><br>
        <p style="color: red;" class="col-sm-6">1. ASUS BT-500 Bluetooth<br> 2. Intel Realsense camera (top)<br> 3. Intel Realsense camera (bottom)<br> 4. Hokuyo LIDAR<br> 5. Roboclaw Motor Driver<br> 6. JABRA Bluetooth Speaker and Mic<br> 7. Galaxy touch screen control (For display)<br>8. Arm Cortex M3 (USB to UART)<br> 9. Arduino Leonardo (USB TO UART)<br> </p>
      </div><br><br>
        <p> The ultrasonic sensors or <b>Range sensors (left image)</b> are connected to the <b>Circuit board (right image)</b> which is embedded with 
          the arm-M3 processor. It also contains all of the power electronic circuit to deliver power to all of the sub subsystems of the Robot.<br><br>
          <div class="row">
          <img src="images/Ultrasonic_sensors.jpg" class="col-sm-6">
          <img src="images/Circuit.jpg" class="col-sm-6"><br><br>
        </div><br><br>
          <p>The motors are controlled by a <b>Motor driver (left image)</b> connected to Arm processor board and power electronic circuit board.The control commands are given to the <b>Arduino Leonardo (right image)</b> and the arm processor.
          The arm processor controlls all of the interactions with the motor, LED strips and ultrasonic sensors while the arduino handles the LED strip around the robot.</p>
          </p>
        <div class="container-fluid">
          <div class="row">
          <img src="images/Motor_driver.jpg" class="col-sm-6"><img src="images/Arduino_Leonardo.jpg" class="col-sm-6">
        </div> 
      </div><br><br> 
         <p> To turn on the Robot simply push the breaker up. Press the power button on the CPU to turn ON the Robot.
        </p><br><br>
        <img src="images/Push_breaker.jpg" style="display:block;margin-left: auto;margin-right:auto;width:50%;height:auto;"><br><br>
        <p>There is also an emergency stop push button on the left side of the robot. This is a Hardware switch that is directy wired to motor controller. Push the button 
          to immediately <b>stop the Robot (left image)</b>. Turn it clockwise to <b>release the push button (right image)</b>.
        </p><br>
        <div class="row">
        <img src="images/button_push.jpg" class="col-sm-6">
        <img src="images/button_rotate.jpg" class="col-sm-6">
        </div><br><br>
        <h2 class="mb-4">Battery</h2>
        <p>The current battery is Li-time rechargable LiFePo (Lithium Iron Phosphate) battery rated for 12V 50Ah. Two of these batteries are connected in series to make 24V. The battery is connected using ring terminals 
          of the appropriate size crimped to the wire. Down below shows an image of the battery connected with ring connectors.<br>
          <a href="https://www.amazon.com/12V-50Ah-LiFePO4-Trolling-Lifetime/dp/B0CT5QT7DJ/ref=sr_1_13?crid=A0ZF0OBPCD91&dib=eyJ2IjoiMSJ9.6to-VLysLCgxx5k_FHTjDrFWfZ8644AQwJHdtp0NVWsFA2MsdtOY_v_jl-9hodRF0wCkCm-0eQrQI9M5eF7u0iLddmI5jD95hSPa0YMY5lyNdsLCF5kXtWlo17fiQsVSUewWY8Fe3ajar0nGHt-YVu5KSfIeVQnjsv3lQYWxFLPOyEBx9ywcQT2cPv4xs68Mkb-W8Z9gHntXpSCvPJ63ACgSM_-idMsxl5ua8eT5gfI.W8J-TwqrlF2-yHJhMZ1vkf5pPYJa7Rzdl1UCGurpJ0s&dib_tag=se&keywords=24%2Bvolt%2Blithium%2Bbattery%2B50ah&qid=1711419626&sprefix=24%2BVolt%2BLithium%2BBattery%2B50%2Caps%2C175&sr=8-13&th=1">Battery Amazon Link</a>
        </p> <br><br>
          <img src="images/Battery.jpg" style="display:block;margin-left: auto;margin-right:auto;width:50%;height:auto;"><br><br>
        <h2 class="mb-4">Charging</h2>
        <p>There are two ways to charge the battery. <br>1. Set the charger to 24V and charge both batteries at the same time. <br>2. Set the charger to 12V and charge one battery at a time.<br> The advantage of 
          the first method is charging both batteries at the same time but leads to uneven battery charging in the long run. The first method is good if the battery are regularly checked and balanced. This can
          be overcome by using the second method. Make sure the battery voltages are same or close to each other.<br><br>
          Connect the batteries to the charger as shown in the image.</p>
          <p>To set the battery at 24V,12V mode simply press the black button on the charger until the <b>LiFePo mode (right image) </b> lights up. This mode works on both 12 and 24V mode and also has 
            a <b>floating battery maintainer (right image)</b> which helps maintain the battery for a very long time. 
          </p>   
          <p><b>Warning : Turn ON the charger before connecting to the battery terminals, connecting the terminals without turning ON the battery will short the battery terminals. The BMS will protect the battery
            from short circuits.
          </b></p>
          <br><br>
        <div class="row">   
        <img src="images/Charging.jpg" class="col-sm-6"><br><br>
        <img src="images/Charger_mode.jpg" class="col-sm-6"><br><br>
        </div><br><br>
          If the battery is going to stay idle then the best way to keep them safe is to put the charger on float mode and 
          connect them to the battery, this allows the battery to stay idle for even months. It is advised to remove the batteries every couple of months, connect them in parallel and balance out the uneven voltage (as shown in the image).
        </p><br><br>
        <img src="images/Battery_instructions.jpg" style="display:block;margin-left: auto;margin-right:auto;width:40%;height:auto;"><br><br>
        <h2 class="mb-4">Harware Upgrades and Changes</h2>
        <table class="table table-bordered">
          <tr>
          <th>S.no</th>
          <th>Component</th>
          <th>Old</th>
          <th>New</th>
        </tr>
        <tr>  
          <td>1</td>
          <td>Battery</td>
          <td><img src="images/Battery_old.jpg" style="width:100%;height:auto;margin:5px"><br>
            <ul>
              <li>WEIZE 12V Reachargable battery</li>
              <li>Lead Acid AGM type battery</li>
              <li>Capacity : 20Ah</li>
              <li>No BMS</li>
              <li>No cycles mentioned</li>
            </ul>
          </td>
          <td>
            <img src="images/Battery.jpg" style="width:80%;height:auto;margin:5px"><br>
            <ul>
              <li>LiTime 12V Plus </li>
              <li>LiFePO4 Lithium Battery</li>
              <li>Capacity : 50Ah</li>
              <li>Built in BMS to protect from overcharging, overdischarging, shortcircuit protection etc</li>
              <li>Over 4000+ cycles of charging and discharging</li>
            </ul>
            
          </td>
        </tr>

        <tr>  
          <td>2</td>
          <td>NUC</td>
          <td>
            <img src="images/old_cpu_crop.jpg" style="width:50%;height:auto;">
            <ul>
              <li>Intel NUC6I5SYH </li>
              <li>Processor : Intel® Core™ i5-6260U Processor (4M Cache, up to 2.90 GHz)</li>
              <li>RAM : 16GB DDR4-2133 1.2V SO-DIMM</li>
              <li>Storage : 128GB SSD</li>
            </ul>

          </td>
          <td>
            <img src="images/CPU.jpg" style="width:70%;height:auto;">
            <ul>
              <li>GEEKOM IT13 Mini PC</li>
              <li>Processor : 13th Intel Core i7-13620H (10C/16T, up to 4.9GHz),</li>
              <li>RAM :  32GB DDR4 RAM/li>
              <li>Storage : 1TB PCIe Gen4</li>
            </ul>
          </td>
        </tr>

        <tr>  
          <td>3</td>
          <td>Realsense Camera</td>
          <td>
            <img src="images/Realsense_camera_old.jpg" style="width:50%;height:auto;">
            <ul>
              <li>RGB-D camera Intel Realsense R200: Pointcloud</li>
              <li>IR and RGB streams. USB 3.0 interface</li>
              <li>Depth capture from 0.4 to 2.8m</li>
              <li>Resolution : 1920x1080 for color camera and 640x480 for Infra red camera</li>
            </ul>
          </td>
          <td>
            <img src="images/depth-camera-d456ip_under_720px.png" style="width:50%;height:auto;">
            <ul>
              <li>Intel realsense D456 camera</li>
              <li>Stero Depth Camera with USB C</li>
              <li>0.6 m to 6 m depth and a resolution of 	less than 2% at 4m</li>
              <li>Resolution : 1920x1080 for color camera and Up to 1280 x 720 stereo depth resolution</li>
            </ul>
          </td>

        </tr>

        <tr>
          <td>4</td>
          <td>Front and Back plates</td>
          <td>
            <img src="images/old_camera_plate1.jpg" style="width:50%;height:auto;"><img src="images/old_camera_plate2.jpg" style="width:50%;height:auto;">
            <ul>
              <li>Old plates to hold the realsense R200 camera</li>
            </ul>
          </td>
          <td>
            <img src="images/New_camera_plate_1.jpg" style="width:50%;height:auto;"><img src="images/new_camera_plate2.jpg" style="width:50%;height:auto;">
            <ul>
              <li>New plates are designed to fit the new camera.</li>
            </ul>
            
          </td>
        </tr>

        <tr>
          <td>5</td>
          <td>NUC power supply circuit</td>
          <td>
            <img src="images/Old_supply.jpg" style="width:50%;height:auto;"><img src="images/Old_connector.jpg" style="width:50%;height:auto;">
            <ul>
              <li>The old NUC takes the supply from the circuit board itself and powers the NUC.</li>
              <li>However the circuit is desgined and biased only for the power capacity of the Intel NUC6I5SYH.</li>
              <li>The Intel NUC is rated for 19V and a power requirement of 15W. </li>
              <li>The voltage reading at the supply pin (in the leftmost picture) measures around 18.8 V and a max current of 3A</li>
            </ul>
          </td>
          <td>
            <img src="images/new_NUC_circuit.jpg" style="width:50%;height:auto;"><img src="images/CPU_connector.jpg" style="width:50%;height:auto;">
            <ul>
              <li>The power supply is bypassed and tapped from the source (leftmost picture) to power the new GEEKOM IT13 MiniPC.</li>
              <li>To power the circuit a buck converter is used to bring down the voltage from 24V to 19V.</li>
              <li>The newly added supply connector is shown in the rightmost image.</li>
              <li>The GEEKOM PC is rated for 19V and 90W of power.</li>
            </ul>
          </td>
        </tr>


        </table><br><br>
        <h4>More about the new NUC power circuit</h4>
        <p>As mentioned earlier the power supply is tapped and used to power the new GEEKOM NUC. The 24V power supply input is 
          bucked down to 19V and given as input to the NUC.The robots body is connected to ground (All of component's ground connections are screwed to robots body), 
          one side of the buck conveter exposes the conductive PCB copper trace and components. Placing it directly on the robot would cause a dead short and completely 
          burn the buck converter components.   
          For this very reason, the buck converter is carefully placed on an insulating acrylic sheet and sticked to the robot using very strong double sided tape. 
           An image of the buck converter is shown below.</p>
          <img src="images/Buck_converter.jpg" style="width:20%;height:auto;display:block;margin-left: auto;margin-right: auto;"><br><br>
        <p>The buck converter is capable of handling a maximum of 8A of current. The wires are also rated for handling such high current.</p>
        <p>
          The power block as shown in the image down below is tapped, a T joint is made to connect one wire going to power the main circuit 
          board and the other to power the NUC through the buck converter.
        </p><br><br>
        <img src="images/NUC_new_supply_1.jpg" style="width:40%;height:auto;display:block;margin-left: auto;margin-right: auto;"><br><br>
         <p> 
          The schematic circuit diagram of the system is shown below.  
        </p>
        <img src="images/NUC_supply_circuit.png" style="width:80%;height:auto;display:block;margin-left: auto;margin-right: auto;"><br><br>

        <h2 class="mb-4">ROS drivers</h2><br>
        <h4>Basics</h4>
        <p>The robot uses ROS melodic. The ROS drivers are found in the ubuntu home named as "Ros_ws". The "src/keylo_bringups" inside the workspace contain 
          the launch files required to launch all the ROS nodes. The other packages are depend on the "keylo_bringup" package and are essential to run all the main packages 
          <img src="images/keylo_bringup.png" style="display:block;margin-left:auto;margin-right:auto;height:auto;width:150%">   
        </p><br>
        <p>A list of launch files in the "keylo_bringup" is shown in the image below.</p><br>
        <img src="images/keylo_launch.png" style="display:block;margin-left:auto;margin-right:auto;height:auto;width:150%"><br><br>
        The important testing launch file are placed under "test" folder.<br><br>   
        <h4>Teleoperation</h4><br>
        To teleoperate the robot, the motors controllers must be run using the ROS launch file.<br> 
        <pre data-src="plugins/toolbar/prism-toolbar.js" data-prismjs-copy="Copy"><code class="language-terminal">roslaunch keylo_bringup trial_keylo_base.launch</code></pre>
        <br><p>This launch files launches all the base sensors and motors of keylo.</p>
        <p>Connect the joystick to the robot using bluetooth. The correct input directory must be selected for the connected joystick. Run the command down below to list the connected joystick inputs.</p>
        <pre data-src="plugins/toolbar/prism-toolbar.js" data-prismjs-copy="Copy"><code class="language-terminal">jstest-gtk</code></pre><br><br>
        <img src="images/joystick_gtk.png" style="display:block;margin-left:auto;margin-right:auto;height:auto;width:50%"><br><br>
        <p>Note that the frist input (/dev/input/js0) is our wireless controller, the second one (/dev/input/js1) is the input from the touch screen display of the Robot. </p>
        <p> Test the joystick using the "jstest" command as given below. Add the appropriate subdirectory with the command.</p>
        <pre data-src="plugins/toolbar/prism-toolbar.js" data-prismjs-copy="Copy"><code class="language-terminal">jstest /dev/input/js0</code></pre><br><br> 
        <img src="images/jstest.png" style="display:block;margin-left:auto;margin-right:auto;height:auto;width:50%"><br><br>
        <p>Before we run teleoperate the robot, some basic parameters must be checked. Navigate to the launch file and check the param file 
          that is linked with the launch file. Change parameters as necessary, by default the enables buttons for normal and turbo modes are L1 and L2 
          respectively. The velocity values can also be adjusted.
        </p><br><br>
        <div class="container-fluid">
          <div class="row">
          <img src="images/joy_launch.png" class="col-sm-6"><img src="images/joy_params.png" class="col-sm-6">
        </div><br><br> 
        <p>The teleop can be achieved by running the following command. Make sure to add the right subdirectory.</p>
        <pre data-src="plugins/toolbar/prism-toolbar.js" data-prismjs-copy="Copy"><code class="language-terminal">roslaunch teleop_twist_joy teleop.launch joy_dev:=/dev/input/js1</code></pre><br><br>
        Hold the shoulder button (L1 - normal , L2 - turbo) and push the thumbstick to run the robot.<br><br>
        <h4>Mapping</h4><br>
         <p>To map the floor, the sensors of the robot, especially the LIDAR and motor controllers must be launched. To launch the sensors on the robot, run the launch file</p>
         <pre data-src="plugins/toolbar/prism-toolbar.js" data-prismjs-copy="Copy"><code class="language-terminal">roslaunch keylo_bringup trial_wyca_till_laser_pointcloud.launch</code></pre><br><br>   
        <p><b>Warning : It is recomended to push the red emergency button down before proceeding to run the above command. With the teleop not running , the 
          program will take the touch screen input xy and starts moving the robot. Avoid this by pressing the red button, release the button once the teleop launch file is run. </b></p>
         <p>The ROS navigation stack uses a map based navigation. One of best methods to generate maps is SLAM (Simultaneous Localization And Mapping), which simultaneously localized and maps the robot. The map is generated using gmapping_slam toolbox
          of ROS to map the robot. The launch files takes in LIDAR topic as argument, in our case we use "/scan_nan_cleaned".</p> <br><br>
          <pre data-src="plugins/toolbar/prism-toolbar.js" data-prismjs-copy="Copy"><code class="language-terminal">rosrun gmapping slam_gmapping scan:=scan_nan_cleaned</code></pre><br><br>
          <p>Open rviz and add the "/map" topic for real time mapping visualization</p>
          <img src="images/rviz_mapping.png" alt="rviz_mapping" style="display:block;margin-left:auto;margin-right:auto;height:auto;width:30%"><br>
          <p>Now move around the robot and map the surrounding. Once the mapping is done use the map server to save the generated map. </p>
          <pre data-src="plugins/toolbar/prism-toolbar.js" data-prismjs-copy="Copy"><code class="language-terminal">rosrun map_server map_saver</code></pre><br><br>
          <p>Additionally you can also specify the name of the image file and resolution as ROS arguments. </p>
          <p>Now the take the saved map and put it inside the folder <b>Ros_ws\src\keylo_config\ROS\ces_keylo\map</b> and rename the pgm file as <b>"map_amcl.pgm"</b>.</p>  
        <h4>Autonomous Navigation</h4><br>
        <p>The launch file for the navigation stack of keylo robot is also under the "keylo_bringup" folder. But the "test_no_front_end.launch" file under the "test" folder 
        launches all the necessary launch files required for navigation and teleoperation. </p>
    
        <p>To run the navigation stack of the Robot along with the localization (amcl particles), global, local costmap, map server, global and local trajectory planner, the command shown below is used to run the test_no_front_end launch file which does all of it. </p>
        <p>The driver uses "mbf_costmap_nav" package for costmaps and path planning. The abbrevation of mbf is "Move Base Flexible" which is a flexible version of the 
          traditional "move_base" package that gives freedom and flexibility to tune more navigation parameters. 
        </p>
        <pre data-src="plugins/toolbar/prism-toolbar.js" data-prismjs-copy="Copy"><code class="language-terminal">roslaunch keylo_bringup test_no_front_end</code></pre><br><br>
        <img src="images/test_no_front_end.png" alt="test_no_front"  style="display:block;margin-left:auto;margin-right:auto;height:auto;width:30%">
        <br><br>
        <p>It is also required to run the <b>rviz_to_mbf.py</b> under <b>Ros_ws\src\keylo_bringup\launch\mbf_legacy\ folder.</b></p>
        <pre data-src="plugins/toolbar/prism-toolbar.js" data-prismjs-copy="Copy"><code class="language-terminal">python rviz_to_mbf.py</code></pre><br><br>
        <p>Now to navigate the robot to the desired location, simply click on "2D Nav goal". Hold to set the position and orientation of the goal location. This will make the robot plan the path to the </p>
        <img src="images/nav_goal.png" alt="test_no_front"  style="display:block;margin-left:auto;margin-right:auto;height:auto;width:30%">
        <p>
          Tuning is also an important aspect of the navigation. The paramaters for tuning will be available under <b> Ros_ws\src\keylo_config\ROS\ces_keylo\nav\costmap_common_params.yaml</b> file. 
          "obstacle_range" and "inflation_radius" are the two most important parameters to tune. 
        </p>
        <img src="images/common_costmap_params.png" alt="test_no_front"  style="display:block;margin-left:auto;margin-right:auto;height:auto;width:80%"><br><br>
        <h4>Realsense Drivers</h4><br>
        <p>To install the realsense drivers for ROS melodic visit the Github Repo of realsense website, <a href="https://github.com/IntelRealSense/realsense-ros/tree/ros1-legacy">https://github.com/IntelRealSense/realsense-ros/tree/ros1-legacy</a>
        Install from the ubuntu apt package manager or build the drivers from source </p>
        <pre data-src="plugins/toolbar/prism-toolbar.js" data-prismjs-copy="Copy"><code class="language-terminal">roslaunch realsense2_camera rs_camera.launch      # To launch a single camera
roslaunch realsense2_camera rs_multiple.launch    # To launch multiple cameras</code></pre><br><br>

        <h2 class="mb-4">Talking Avatar</h2><br>
          The talking avatar is a opensource program from <a href="https://github.com/bornfree/talking_avatar">https://github.com/bornfree/talking_avatar</a>. This react applications uses webRendering of the avatar
          with 3D animations. The backend of this program at <a href="https://github.com/bornfree/talking_avatar_backend">https://github.com/bornfree/talking_avatar_backend</a> is node application that uses azure_api in the backend 
          to convert text to speech and animate lip movements. The azure api only provides some hours of free audio api request, after which it becomes paid.
          The image down below shows the web application running in the browser as a local host. <br><br>
          <img src="images/live_avatar.png" style="display:block;margin-left: auto;margin-right:auto;width:100%;height:auto;"><br><br>
          <p>To run the front end react application simply cd into the folder, type the following command to install all the necessary dependencies and the next command runs the react application.   
          </p>
          <pre data-src="plugins/toolbar/prism-toolbar.js" data-prismjs-copy="Copy"><code class="language-terminal">yarn install # Install all the necessary dependencies           
yarn start # Start the App </code></pre><br><br>
          <p>Note that there is a start button. The start button must be pressed in order to initiate the voice interaction. Note that the start button is necesarry because the audio 
          of any webpage will only start if there is some events that is triggered intially. This feature is bought forth for security purposes.
          <br>
          The voice to text recognition model is running in python. It uses the "vosk" speech recognition model to convert speech to text.</p><br><br> 
          <img src="images/vosk_model.png"  style="display:block;margin-left:auto;margin-right:auto;height:auto;width:100%"><br><br>
          <pre data-src="plugins/toolbar/prism-toolbar.js" data-prismjs-copy="Copy"><code class="language-python">from vosk import Model, KaldiRecognizer
import requests
import pyaudio
import json


url = “http://localhost:5000/speech_out"™
headers = {'Content-type': ‘application/json', ‘Accept’: ‘text/plain'}
model = Model("“vosk-model-en-us-9.22")

recognizer = KaldiRecognizer(model, 16000)

mic = pyaudio.PyAudio()
stream = mic.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=8192)
stream.start_stream()
stripped_data = ""

while True:
  data = stream.read(4096,exception_on_overflow=False)
  print("...")
  if recognizer .AcceptWaveform(data) :
    text = recognizer.Result()
    #print (f"{text[14:-3]}")
    stripped_data = text[14:-3]
    data = {'msg':stripped_data}
    print(data)
    r = requests.post (url, data=json.dumps (data) ,headers=headers)
    print(r.status_code)</code></pre><br><br>
          <p>The text is then sent as a json using post requests to the node server. The "talking_avatar_backend" receives the request using the post method.
            To install all dependencies, run the node server, use the commands below 
          </p>
          <pre data-src="plugins/toolbar/prism-toolbar.js" data-prismjs-copy="Copy"><code class="language-terminal">npm install # Install all the necessary dependencies           
npm start # Start the Node server </code></pre><br><br>
          <p>The openai api runs in backend of the system, the image down below shows the openai api running in the backend of the system.</p><br><br> 
          <img src="images/Openai_api_call.png"  style="display:block;margin-left:auto;margin-right:auto;height:auto;width:100%"><br><br>

          <p>The modified code for front and back end of the is available in the github repo : For front end <a href="https://github.com/sridharanram2001/talking_avatar">https://github.com/sridharanram2001/talking_avatar</a> and backend <a href="https://github.com/sridharanram2001/talking_avatar_backend">https://github.com/sridharanram2001/talking_avatar_backend</a></p>

      </div>
		</div>

    <script src="js/jquery.min.js"></script> 
    <script src="js/popper.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/main.js"></script>
  </body>
</html>